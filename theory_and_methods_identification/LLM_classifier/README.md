# LLM Classifier Module

This Python module provides a framework for classifying text data using Large Language Models (LLMs). It is designed to be abstract and extensible, allowing for the creation of custom classifiers for various tasks by defining specific prompts and data models.

---

## Core Concepts

The classifier operates on a staged approach:

1.  **Category Discovery**: An initial set of categories is generated by an LLM based on a sample of the data.
2.  **Batch Classification**: The full dataset is classified using the generated categories. The LLM can also identify and add new categories during this process.
3.  **Category Review**: The list of categories is reviewed and refined by an LLM to merge duplicates, remove irrelevant entries, and improve overall quality.
4.  **Re-classification**: After the categories have been reviewed and improved, the classification process is run again on the original dataset. This ensures that the final classifications are based on the cleaned and more coherent set of categories.
5.  **Meta-Categorization**: The refined categories can then be classified into higher-level meta-categories, providing a more abstract view of the data.

This entire workflow is orchestrated through a set of abstract base classes that can be extended to suit specific needs.


---

## Key Features

* **Abstract by Design**: The core logic is implemented in abstract base classes (`BaseClassifier`, `SectionClassifier`, `CategoryClassifier`), allowing for easy extension to any LLM-based classification task.
* **Pydantic Models**: Data validation and LLM return format is handled through Pydantic models, ensuring that the data passed to and received from the LLM is structured and type-safe.
* **Customizable Prompts**: The behavior of the classifier is controlled through prompts that can be tailored to the specific domain and task.
* **Batch Processing**: Efficiently classify large datasets.
* **Cost Estimation**: Estimate the cost of classification tasks before execution to manage API usage and costs.

---

## How to Create a Custom Classifier

To create a custom classifier, you need to inherit from one of the abstract base classes and implement the abstract methods. The primary methods to implement are those that provide the prompts for the LLM.

### Example: `TheoreticalFrameworkClassifier`

This classifier is designed to identify and classify theoretical frameworks in academic articles. It inherits from `SectionClassifier` and provides specific prompts for this task.

```python
from LLM_classifier.classifiers.section_classifier import SectionClassifier
from LLM_classifier.models.base_models import CategoryTemperatureLevel
from typing import Tuple

class TheoreticalFrameworkClassifier(SectionClassifier):
    """
    Specific classifier for theoretical framework sections.
    """

    @property
    def temperature_levels(self) -> CategoryTemperatureLevel:
        # ... implementation ...
        pass

    def get_classification_prompts(self, element_data, categories, category_creation_temperature) -> Tuple[str, str]:
        # ... implementation ...
        pass

    def get_category_discovery_system_prompt(self) -> str:
        # ... implementation ...
        pass

    def get_category_review_prompts(self, categories) -> Tuple[str, str]:
        # ... implementation ...
        pass
```

### Advanced Customization with `BaseClassifier`

For complete control over the data types used for classification, you can inherit directly from the main `BaseClassifier`. This allows you to define custom Pydantic models for your specific input data (`DataType`) and the expected LLM response (`ResponseType`).

This approach is useful when you are not classifying sections of text or categorizing categories, but have a completely different use case.

```python
from LLM_classifier.base import BaseClassifier
from pydantic import BaseModel
from typing import List, Tuple

# 1. Define your custom Pydantic models
class MyCustomData(BaseModel):
    # Your input data structure
    content: str
    metadata: dict

class MyCustomResponse(BaseModel):
    # The expected structure of the LLM's response
    sentiment: str
    confidence: float
    keywords: List[str]

# 2. Create a custom classifier by inheriting from BaseClassifier
class CustomSentimentClassifier(BaseClassifier[MyCustomResponse, MyCustomData, ...]): # Other types as needed

    def get_classification_prompts(self, element_data: MyCustomData, categories: List, ...) -> Tuple[str, str]:
        system_prompt = "You are a sentiment analysis expert..."
        user_prompt = f"Analyze the following text: {element_data.content}"
        return system_prompt, user_prompt

    # ... implement other abstract methods ...
```